{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices Competition : Term Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import neighbors\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(style='ggplot')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data from feature engineering notebook\n",
    "%store -r train_set_1\n",
    "%store -r test_set_1\n",
    "%store -r ytrain_1\n",
    "\n",
    "train_set = train_set_1\n",
    "test_set = test_set_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_Con</th>\n",
       "      <th>SaleType_ConLD</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>Street_Grvl</th>\n",
       "      <th>Street_Pave</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>284.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  Alley  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       856       854          0      0             3       706.0         0.0   \n",
       "1      1262         0          0      0             3       978.0         0.0   \n",
       "2       920       866          0      0             3       486.0         0.0   \n",
       "3       961       756          0      0             3       216.0         0.0   \n",
       "4      1145      1053          0      0             4       655.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF    ...      SaleType_Con  \\\n",
       "0           1.0             0      150.0    ...                 0   \n",
       "1           0.0             1      284.0    ...                 0   \n",
       "2           1.0             0      434.0    ...                 0   \n",
       "3           1.0             0      540.0    ...                 0   \n",
       "4           1.0             0      490.0    ...                 0   \n",
       "\n",
       "   SaleType_ConLD  SaleType_ConLI  SaleType_ConLw  SaleType_New  SaleType_Oth  \\\n",
       "0               0               0               0             0             0   \n",
       "1               0               0               0             0             0   \n",
       "2               0               0               0             0             0   \n",
       "3               0               0               0             0             0   \n",
       "4               0               0               0             0             0   \n",
       "\n",
       "   SaleType_WD  Street_Grvl  Street_Pave  SalePrice  \n",
       "0            1            0            1     208500  \n",
       "1            1            0            1     181500  \n",
       "2            1            0            1     223500  \n",
       "3            1            0            1     140000  \n",
       "4            1            0            1     250000  \n",
       "\n",
       "[5 rows x 292 columns]"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (1452, 292)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train data shape:\", train_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_CWD</th>\n",
       "      <th>SaleType_Con</th>\n",
       "      <th>SaleType_ConLD</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>Street_Grvl</th>\n",
       "      <th>Street_Pave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 291 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1stFlrSF  2ndFlrSF  3SsnPorch  Alley  BedroomAbvGr  BsmtFinSF1  \\\n",
       "1452       896         0          0      0             2       468.0   \n",
       "1453      1329         0          0      0             3       923.0   \n",
       "1454       928       701          0      0             3       791.0   \n",
       "1455       926       678          0      0             3       602.0   \n",
       "1456      1280         0          0      0             2       263.0   \n",
       "\n",
       "      BsmtFinSF2  BsmtFullBath  BsmtHalfBath  BsmtUnfSF     ...       \\\n",
       "1452       144.0           0.0             0      270.0     ...        \n",
       "1453         0.0           0.0             0      406.0     ...        \n",
       "1454         0.0           0.0             0      137.0     ...        \n",
       "1455         0.0           0.0             0      324.0     ...        \n",
       "1456         0.0           0.0             0     1017.0     ...        \n",
       "\n",
       "      SaleType_CWD  SaleType_Con  SaleType_ConLD  SaleType_ConLI  \\\n",
       "1452             0             0               0               0   \n",
       "1453             0             0               0               0   \n",
       "1454             0             0               0               0   \n",
       "1455             0             0               0               0   \n",
       "1456             0             0               0               0   \n",
       "\n",
       "      SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  Street_Grvl  \\\n",
       "1452               0             0             0            1            0   \n",
       "1453               0             0             0            1            0   \n",
       "1454               0             0             0            1            0   \n",
       "1455               0             0             0            1            0   \n",
       "1456               0             0             0            1            0   \n",
       "\n",
       "      Street_Pave  \n",
       "1452            1  \n",
       "1453            1  \n",
       "1454            1  \n",
       "1455            1  \n",
       "1456            1  \n",
       "\n",
       "[5 rows x 291 columns]"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (1459, 291)\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data shape:\", test_set.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_Con</th>\n",
       "      <th>SaleType_ConLD</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>Street_Grvl</th>\n",
       "      <th>Street_Pave</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>284.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  Alley  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       856       854          0      0             3       706.0         0.0   \n",
       "1      1262         0          0      0             3       978.0         0.0   \n",
       "2       920       866          0      0             3       486.0         0.0   \n",
       "3       961       756          0      0             3       216.0         0.0   \n",
       "4      1145      1053          0      0             4       655.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF    ...      SaleType_Con  \\\n",
       "0           1.0             0      150.0    ...                 0   \n",
       "1           0.0             1      284.0    ...                 0   \n",
       "2           1.0             0      434.0    ...                 0   \n",
       "3           1.0             0      540.0    ...                 0   \n",
       "4           1.0             0      490.0    ...                 0   \n",
       "\n",
       "   SaleType_ConLD  SaleType_ConLI  SaleType_ConLw  SaleType_New  SaleType_Oth  \\\n",
       "0               0               0               0             0             0   \n",
       "1               0               0               0             0             0   \n",
       "2               0               0               0             0             0   \n",
       "3               0               0               0             0             0   \n",
       "4               0               0               0             0             0   \n",
       "\n",
       "   SaleType_WD  Street_Grvl  Street_Pave  SalePrice  \n",
       "0            1            0            1     208500  \n",
       "1            1            0            1     181500  \n",
       "2            1            0            1     223500  \n",
       "3            1            0            1     140000  \n",
       "4            1            0            1     250000  \n",
       "\n",
       "[5 rows x 292 columns]"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = train_set.select_dtypes(include=[np.number]).interpolate().dropna()\n",
    "test_set = test_set.select_dtypes(include=[np.number]).interpolate().dropna()\n",
    "train_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#num_columns_train = train_set.select_dtypes(include = [np.number]).columns.values.tolist()\n",
    "#num_columns_test = test_set.select_dtypes(include = [np.number]).columns.values.tolist()\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#train_set.loc[:,num_columns_train] = scaler.fit_transform(train_set[num_columns_train])\n",
    "#test_set.loc[:,num_columns_test] = scaler.fit_transform(test_set[num_columns_test])\n",
    "\n",
    "\n",
    "#print(train_set.head())\n",
    "#print(test_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = train_set.SalePrice\n",
    "y = np.log(train_set.SalePrice)\n",
    "X = train_set.drop(['SalePrice'] , axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0736579 ,  1.03167677,  1.02673244,  1.0238889 ,  1.02276893,\n",
       "        1.01835754,  1.01627815,  1.01571762,  1.01227967,  1.01218986,\n",
       "        1.01185609,  1.01121494,  1.01066472,  1.010115  ,  1.00984465,\n",
       "        1.00965544,  1.00933163,  1.00929842,  1.00894703,  1.00862904,\n",
       "        1.00842767,  1.00815987,  1.00809376,  1.00795234,  1.00777686,\n",
       "        1.00769734,  1.00740914,  1.00727205,  1.00717364,  1.00714517])"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)                \n",
    "t_train = scaler.transform(X)\n",
    "pca_hp = PCA(30)\n",
    "x_fit = pca_hp.fit_transform(t_train)\n",
    "np.exp(pca_hp.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split() returns four objects:\n",
    "\n",
    "* X_train is the subset of our features used for training.\n",
    "* X_test is the subset which will be our 'hold-out' set - what we'll use to test the model.\n",
    "* y_train is the target variable SalePrice which corresponds to X_train.\n",
    "* y_test is the target variable SalePrice which corresponds to X_test. \n",
    "\n",
    "random_state=42 allow reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                   X, y, random_state=42, test_size=.33)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#scalerX = MinMaxScaler().fit(X_train)\n",
    "#scalery = MinMaxScaler().fit(y_train.reshape(-1,1))\n",
    "#X_train = scalerX.transform(X_train)\n",
    "#y_train = scalery.transform(y_train.reshape(-1,1))\n",
    "#X_test = scalerX.transform(X_test)\n",
    "#y_test = scalery.transform(y_test.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is:  0.875852404421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Fit Random Forest on Training Set\n",
    "regressor = RandomForestRegressor(n_estimators=300, random_state=0)\n",
    "model_random_forest = regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Score model\n",
    "print (\"Test score is: \", model_random_forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.019184894702\n"
     ]
    }
   ],
   "source": [
    "predictions_1 = model_random_forest.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best k number\n",
    "\n",
    "ourScore=[]\n",
    "for nn in range(1,15):\n",
    "    knn = neighbors.KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                                        metric_params=None, n_jobs=1, n_neighbors=nn,p=2,\n",
    "                                        weights='uniform')\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    #print('k: %d, Train Acc: %.3f, Test Acc: %.3f' % (nn, train_score, test_score))\n",
    "    rowScore=[nn,train_score,test_score]\n",
    "    ourScore.append(rowScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 5, Train Acc: 0.804, Test Acc: 0.680\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "knn = neighbors.KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "          metric_params=None, n_jobs=1, n_neighbors=k, p=2,\n",
    "          weights='uniform')\n",
    "knn.fit(X_train, y_train)\n",
    "train_score = knn.score(X_train, y_train)\n",
    "test_score = knn.score(X_test, y_test)\n",
    "\n",
    "print('k: %d, Train Acc: %.3f, Test Acc: %.3f' % (k, train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.0494293297457\n"
     ]
    }
   ],
   "source": [
    "predictions_2 = knn.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " -345840.431275\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "regressor = LinearRegression() \n",
    "regressor.fit(X_train, y_train) \n",
    "print (\"Test score is: \\n\", regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 53443.8980607\n"
     ]
    }
   ],
   "source": [
    "predictions_3 = regressor.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with ridge regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check what alpha value is better for the model\n",
    "\n",
    "for i in range (-5, 5):\n",
    "    alpha = 10**i\n",
    "    rm = linear_model.Ridge(alpha=alpha)\n",
    "    ridge_model = rm.fit(X_train, y_train)\n",
    "    preds_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "    plt.scatter(preds_ridge, y_test, alpha=.75, color='b')\n",
    "    plt.xlabel('Predicted Price')\n",
    "    plt.ylabel('Actual Price')\n",
    "    plt.title('Ridge Regularization with alpha = {}'.format(alpha))\n",
    "    overlay = 'R^2 is: {}\\nRMSE is: {}'.format(\n",
    "                    ridge_model.score(X_test, y_test),\n",
    "                    mean_squared_error(y_test, preds_ridge))\n",
    "    plt.annotate(s=overlay,xy=(12.1,10.6),size='x-large')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.901239708666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "linm = linear_model.Ridge(alpha = 10)\n",
    "\n",
    "linm.fit(X_train, y_train)\n",
    "print (\"Test score is: \\n\", linm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 0.0152617195777\n"
     ]
    }
   ],
   "source": [
    "predictions = linm.predict(X_test)\n",
    "print(\"Mean Squared Error : \" + str(mean_squared_error(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP with PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp_regressor = MLPRegressor(solver='lbfgs',hidden_layer_sizes = (200,5,5),alpha = 1.0, activation = 'relu', max_iter = 100)\n",
    "#mlp_regressor.fit(X_train,y_train)\n",
    "\n",
    "#print (\"Test score is: \\n\", mlp_regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions7 = mlp_regressor.predict(X_test1)\n",
    "#print(\"Mean Squared Error : \" + str(mean_squared_error(y_test,predictions7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is: \n",
      " 0.999999996944\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "basic_decision_tree = DecisionTreeRegressor()\n",
    "\n",
    "# Fit model\n",
    "basic_decision_tree.fit(X, y)\n",
    "\n",
    "print(\"R^2 is: \\n\", basic_decision_tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 4.72276373045e-10\n"
     ]
    }
   ],
   "source": [
    "predictions_5 = basic_decision_tree.predict(X_test)\n",
    "print(\"Mean Squared Error : \" + str(mean_squared_error(y_test,predictions_5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = np.arange(0.0, 0.09, 0.0015)\n",
    "learning_rates\n",
    "best_learning_rates = [0.0885, 0.0735, 0.0705, 0.0615, 0.06, 0.0585, 0.057, 0.0555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find best parameters\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "actual_values = y_test\n",
    "\n",
    "for i in best_learning_rates:\n",
    "    n_estimators = 1000\n",
    "    my_model = XGBRegressor(n_estimators=n_estimators,learning_rate=i)\n",
    "    xgboost_model = my_model.fit(X_train, y_train, early_stopping_rounds=5, \n",
    "                 eval_set=[(X_test, y_test)], verbose=False)\n",
    "    preds_xgboost = xgboost_model.predict(X_test)\n",
    "\n",
    "    plt.scatter(preds_xgboost, actual_values, alpha=.75, color='b')\n",
    "    plt.xlabel('Predicted Price')\n",
    "    plt.ylabel('Actual Price')\n",
    "    plt.title('XGBoost with  = {}'.format(n_estimators))\n",
    "    overlay = 'R^2 is: {}\\nRMSE is: {}\\nlearning Rate is: {}'.format(\n",
    "                        xgboost_model.score(X_test, y_test),\n",
    "                        mean_squared_error(y_test, preds_xgboost),\n",
    "                        i)\n",
    "    plt.annotate(s=overlay,xy=(12.1,10.6),size='x-large')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: \n",
      " 0.905846405165\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "XGBoost = XGBRegressor(n_estimators = 1000,learning_rate=0.0585)\n",
    "XGBoost.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print (\"Test Score: \\n\", XGBoost.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.0145498331587\n"
     ]
    }
   ],
   "source": [
    "prediction = XGBoost.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: \n",
      " 0.904965675904\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "lasso.fit(X_train, y_train)\n",
    "print (\"Test Score: \\n\", lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.0146859348533\n"
     ]
    }
   ],
   "source": [
    "predictions_lasso = lasso.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_lasso)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: \n",
      " 0.90495230902\n"
     ]
    }
   ],
   "source": [
    "# Elastic Net regression\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "ENet.fit(X_train, y_train)\n",
    "print (\"Test Score: \\n\", ENet.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.0146880004772\n"
     ]
    }
   ],
   "source": [
    "predictions_ENet = ENet.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_ENet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: \n",
      " 0.900061935524\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting regression\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "GBoost.fit(X_train, y_train)\n",
    "print (\"Test Score: \\n\", GBoost.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.0154437243408\n"
     ]
    }
   ],
   "source": [
    "predictions_GBoost = GBoost.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_GBoost)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: \n",
      " 0.902791193686\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "model_lgb.fit(X_train, y_train)\n",
    "print (\"Test Score: \\n\", model_lgb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.0150219640142\n"
     ]
    }
   ],
   "source": [
    "predictions_model_lgb = model_lgb.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_model_lgb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avereging Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enet regression + GBoost + LGBM + Lasso regression (Best Score):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: \n",
      " 0.910253536225\n"
     ]
    }
   ],
   "source": [
    "#Best version\n",
    "averaged_models = AveragingModels(models = (ENet, GBoost, model_lgb, lasso))\n",
    "\n",
    "averaged_models.fit(X_train, y_train)\n",
    "print (\"Test Score: \\n\", averaged_models.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.0138687861764\n"
     ]
    }
   ],
   "source": [
    "predictions = averaged_models.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "#bagging = BaggingRegressor(KNeighborsClassifier(),max_samples=0.5, max_features=0.5)\n",
    "#averaged_models.fit(X_train, y_train)\n",
    "#print (\"Test Score: \\n\", averaged_models.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = averaged_models.predict(X_test)\n",
    "#print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking :\n",
    "Using Meta model with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[  1   2   3   4   5   6   7   8   9  10  11  13  14  16  17  18  19  21\\n  22  23  24  25  26  27  28  29  30  31  32  33  34  36  37  40  41  43\\n  45  46  47  48  49  51  52  53  54  55  57  58  59  60  61  63  64  66\\n  67  68  69  70  73  74  75  76  78  80  81  83  84  85  86  87  91  92\\n  94  95  98  99 100 101 103 104 105 106 107 110 111 112 114 115 118 119\\n 120 122 123 124 125 126 127 128 129 130 131 132 133 134 135 138 139 140\\n 141 142 143 144 145 147 148 149 150 151 153 155 156 157 158 159 160 161\\n 162 163 164 165 167 168 169 170 172 174 175 176 177 178 179 181 182 183\\n 184 185 186 187 188 189 190 192 193 195 198 199 201 202 203 204 205 206\\n 207 208 209 210 211 212 213 214 216 217 218 219 220 221 222 223 224 225\\n 229 230 231 232 233 234 235 236 238 239 241 243 244 245 246 247 248 249\\n 250 251 252 253 254 255 257 258 259 260 261 262 263 265 268 270 272 274\\n 276 277 278 279 280 281 282 283 285 286 287 288 289 291 292 293 294 296\\n 297 298 299 300 302 303 305 307 308 312 313 314 315 316 317 318 319 320\\n 321 322 323 324 325 326 327 328 329 330 331 333 334 335 336 338 339 340\\n 341 342 343 344 345 348 349 350 351 352 353 354 355 356 357 359 360 361\\n 362 363 364 365 366 367 368 369 370 372 373 374 375 376 377 378 380 381\\n 382 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400\\n 401 402 403 404 405 406 408 409 410 411 414 415 416 417 418 419 421 422\\n 423 424 425 427 428 430 431 432 433 434 436 439 440 441 442 443 445 446\\n 447 448 449 450 452 453 454 456 458 459 460 461 462 463 464 465 466 468\\n 469 470 471 472 473 475 476 477 478 480 481 482 483 484 485 486 487 491\\n 492 493 494 496 497 498 499 500 501 502 504 505 507 509 510 513 514 516\\n 517 520 521 523 524 525 526 528 529 530 532 533 535 536 540 542 543 544\\n 545 546 547 549 550 552 553 554 555 556 557 559 560 561 565 566 567 569\\n 570 574 575 576 577 579 581 582 583 584 585 588 589 592 594 595 596 597\\n 598 599 600 601 602 603 605 606 607 608 609 610 611 613 614 615 616 617\\n 619 620 621 623 624 625 626 627 628 629 630 632 633 634 635 637 638 639\\n 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657\\n 658 659 660 661 663 665 666 667 668 669 671 673 674 677 678 681 682 683\\n 684 685 686 687 688 689 691 692 693 694 696 697 698 699 700 701 702 703\\n 705 706 707 708 709 710 711 712 715 716 717 718 719 720 721 723 724 726\\n 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744\\n 745 746 747 748 750 751 752 753 754 755 756 757 758 760 761 762 763 764\\n 765 766 767 769 770 771 772 774 775 776 777 778 779 780 781 782 783 784\\n 785 786 787 788 789 790 791 793 794 795 797 798 799 800 802 803 804 805\\n 806 807 808 809 810 811 812 813 815 816 817 818 819 820 821 822 823 825\\n 826 827 828 830 831 832 834 835 836 837 838 839 840 842 846 847 848 849\\n 850 851 852 853 854 855 856 857 858 859 861 863 864 865 866 867 868 869\\n 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887\\n 889 891 897 899 900 901 903 904 906 907 909 910 911 913 914 916 917 918\\n 919 920 921 922 923 924 926 928 929 930 931 932 933 934 937 938 939 940\\n 941 944 945 946 947 948 953 954 955 956 957 958 959 962 964 965 967 968\\n 969 970 971] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-717-ff7c41ab4594>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost),\n\u001b[0;32m      2\u001b[0m                                                  meta_model = lasso)\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstacked_averaged_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Score: \\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacked_averaged_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstacked_averaged_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-716-64e0719ff84a>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_models_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mholdout_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mout_of_fold_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mholdout_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1956\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2000\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2002\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2003\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1229\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1231\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s not in index'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[  1   2   3   4   5   6   7   8   9  10  11  13  14  16  17  18  19  21\\n  22  23  24  25  26  27  28  29  30  31  32  33  34  36  37  40  41  43\\n  45  46  47  48  49  51  52  53  54  55  57  58  59  60  61  63  64  66\\n  67  68  69  70  73  74  75  76  78  80  81  83  84  85  86  87  91  92\\n  94  95  98  99 100 101 103 104 105 106 107 110 111 112 114 115 118 119\\n 120 122 123 124 125 126 127 128 129 130 131 132 133 134 135 138 139 140\\n 141 142 143 144 145 147 148 149 150 151 153 155 156 157 158 159 160 161\\n 162 163 164 165 167 168 169 170 172 174 175 176 177 178 179 181 182 183\\n 184 185 186 187 188 189 190 192 193 195 198 199 201 202 203 204 205 206\\n 207 208 209 210 211 212 213 214 216 217 218 219 220 221 222 223 224 225\\n 229 230 231 232 233 234 235 236 238 239 241 243 244 245 246 247 248 249\\n 250 251 252 253 254 255 257 258 259 260 261 262 263 265 268 270 272 274\\n 276 277 278 279 280 281 282 283 285 286 287 288 289 291 292 293 294 296\\n 297 298 299 300 302 303 305 307 308 312 313 314 315 316 317 318 319 320\\n 321 322 323 324 325 326 327 328 329 330 331 333 334 335 336 338 339 340\\n 341 342 343 344 345 348 349 350 351 352 353 354 355 356 357 359 360 361\\n 362 363 364 365 366 367 368 369 370 372 373 374 375 376 377 378 380 381\\n 382 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400\\n 401 402 403 404 405 406 408 409 410 411 414 415 416 417 418 419 421 422\\n 423 424 425 427 428 430 431 432 433 434 436 439 440 441 442 443 445 446\\n 447 448 449 450 452 453 454 456 458 459 460 461 462 463 464 465 466 468\\n 469 470 471 472 473 475 476 477 478 480 481 482 483 484 485 486 487 491\\n 492 493 494 496 497 498 499 500 501 502 504 505 507 509 510 513 514 516\\n 517 520 521 523 524 525 526 528 529 530 532 533 535 536 540 542 543 544\\n 545 546 547 549 550 552 553 554 555 556 557 559 560 561 565 566 567 569\\n 570 574 575 576 577 579 581 582 583 584 585 588 589 592 594 595 596 597\\n 598 599 600 601 602 603 605 606 607 608 609 610 611 613 614 615 616 617\\n 619 620 621 623 624 625 626 627 628 629 630 632 633 634 635 637 638 639\\n 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657\\n 658 659 660 661 663 665 666 667 668 669 671 673 674 677 678 681 682 683\\n 684 685 686 687 688 689 691 692 693 694 696 697 698 699 700 701 702 703\\n 705 706 707 708 709 710 711 712 715 716 717 718 719 720 721 723 724 726\\n 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744\\n 745 746 747 748 750 751 752 753 754 755 756 757 758 760 761 762 763 764\\n 765 766 767 769 770 771 772 774 775 776 777 778 779 780 781 782 783 784\\n 785 786 787 788 789 790 791 793 794 795 797 798 799 800 802 803 804 805\\n 806 807 808 809 810 811 812 813 815 816 817 818 819 820 821 822 823 825\\n 826 827 828 830 831 832 834 835 836 837 838 839 840 842 846 847 848 849\\n 850 851 852 853 854 855 856 857 858 859 861 863 864 865 866 867 868 869\\n 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887\\n 889 891 897 899 900 901 903 904 906 907 909 910 911 913 914 916 917 918\\n 919 920 921 922 923 924 926 928 929 930 931 932 933 934 937 938 939 940\\n 941 944 945 946 947 948 953 954 955 956 957 958 959 962 964 965 967 968\\n 969 970 971] not in index'"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost),\n",
    "                                                 meta_model = lasso)\n",
    "stacked_averaged_models.fit(X_train, y_train)\n",
    "print (\"Test Score: \\n\", stacked_averaged_models.score(X_test, y_test))\n",
    "predictions = stacked_averaged_models.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "%store -r test_ID\n",
    "submission['Id'] = test_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = test_set.select_dtypes(\n",
    "        include=[np.number])\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = stacked_averaged_models.predict(feats)\n",
    "predictions\n",
    "#final_predictions = np.exp(predictions)\n",
    "\n",
    "#final_predictions = scalery.inverse_transform(predictions.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission['SalePrice'] = final_predictions\n",
    "#submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"normalize_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
