{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices Competition : Term Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import neighbors\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(style='ggplot')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data from feature engineering notebook\n",
    "%store -r train_set_1\n",
    "%store -r test_set_1\n",
    "%store -r ytrain_1\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "\n",
    "train_set = train_set_1\n",
    "test_set = test_set_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_CWD</th>\n",
       "      <th>SaleType_Con</th>\n",
       "      <th>SaleType_ConLD</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>Street_Grvl</th>\n",
       "      <th>Street_Pave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109641</td>\n",
       "      <td>0.458647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.176060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064212</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.194917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.243890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121575</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.123083</td>\n",
       "      <td>0.465091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.121197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185788</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.131695</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.053865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231164</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.170342</td>\n",
       "      <td>0.565521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.163342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209760</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 291 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  Alley  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0  0.109641  0.458647        0.0      0         0.375    0.176060         0.0   \n",
       "1  0.194917  0.000000        0.0      0         0.375    0.243890         0.0   \n",
       "2  0.123083  0.465091        0.0      0         0.375    0.121197         0.0   \n",
       "3  0.131695  0.406015        0.0      0         0.375    0.053865         0.0   \n",
       "4  0.170342  0.565521        0.0      0         0.500    0.163342         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF     ...       SaleType_CWD  \\\n",
       "0      0.333333           0.0   0.064212     ...                  0   \n",
       "1      0.000000           1.0   0.121575     ...                  0   \n",
       "2      0.333333           0.0   0.185788     ...                  0   \n",
       "3      0.333333           0.0   0.231164     ...                  0   \n",
       "4      0.333333           0.0   0.209760     ...                  0   \n",
       "\n",
       "   SaleType_Con  SaleType_ConLD  SaleType_ConLI  SaleType_ConLw  SaleType_New  \\\n",
       "0             0               0               0               0             0   \n",
       "1             0               0               0               0             0   \n",
       "2             0               0               0               0             0   \n",
       "3             0               0               0               0             0   \n",
       "4             0               0               0               0             0   \n",
       "\n",
       "   SaleType_Oth  SaleType_WD  Street_Grvl  Street_Pave  \n",
       "0             0            1            0            1  \n",
       "1             0            1            0            1  \n",
       "2             0            1            0            1  \n",
       "3             0            1            0            1  \n",
       "4             0            1            0            1  \n",
       "\n",
       "[5 rows x 291 columns]"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (1452, 291)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train data shape:\", train_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_CWD</th>\n",
       "      <th>SaleType_Con</th>\n",
       "      <th>SaleType_ConLD</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>Street_Grvl</th>\n",
       "      <th>Street_Pave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>0.118042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.116708</td>\n",
       "      <td>0.094364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115582</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>0.208990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.230175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173801</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>0.124764</td>\n",
       "      <td>0.376477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.197257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058647</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.124344</td>\n",
       "      <td>0.364125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.150125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138699</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0.198698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.065586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435360</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 291 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1stFlrSF  2ndFlrSF  3SsnPorch  Alley  BedroomAbvGr  BsmtFinSF1  \\\n",
       "1452  0.118042  0.000000        0.0      0         0.250    0.116708   \n",
       "1453  0.208990  0.000000        0.0      0         0.375    0.230175   \n",
       "1454  0.124764  0.376477        0.0      0         0.375    0.197257   \n",
       "1455  0.124344  0.364125        0.0      0         0.375    0.150125   \n",
       "1456  0.198698  0.000000        0.0      0         0.250    0.065586   \n",
       "\n",
       "      BsmtFinSF2  BsmtFullBath  BsmtHalfBath  BsmtUnfSF     ...       \\\n",
       "1452    0.094364           0.0           0.0   0.115582     ...        \n",
       "1453    0.000000           0.0           0.0   0.173801     ...        \n",
       "1454    0.000000           0.0           0.0   0.058647     ...        \n",
       "1455    0.000000           0.0           0.0   0.138699     ...        \n",
       "1456    0.000000           0.0           0.0   0.435360     ...        \n",
       "\n",
       "      SaleType_CWD  SaleType_Con  SaleType_ConLD  SaleType_ConLI  \\\n",
       "1452             0             0               0               0   \n",
       "1453             0             0               0               0   \n",
       "1454             0             0               0               0   \n",
       "1455             0             0               0               0   \n",
       "1456             0             0               0               0   \n",
       "\n",
       "      SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  Street_Grvl  \\\n",
       "1452               0             0             0            1            0   \n",
       "1453               0             0             0            1            0   \n",
       "1454               0             0             0            1            0   \n",
       "1455               0             0             0            1            0   \n",
       "1456               0             0             0            1            0   \n",
       "\n",
       "      Street_Pave  \n",
       "1452            1  \n",
       "1453            1  \n",
       "1454            1  \n",
       "1455            1  \n",
       "1456            1  \n",
       "\n",
       "[5 rows x 291 columns]"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (1459, 291)\n"
     ]
    }
   ],
   "source": [
    "print (\"Test data shape:\", test_set.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([208500, 181500, 223500, ..., 266500, 142125, 147500], dtype=int64)"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we keep the test id to make submission after\n",
    "test_ID = test[\"Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29418743],\n",
       "       [ 0.24843247],\n",
       "       [ 0.31960685],\n",
       "       ..., \n",
       "       [ 0.39247585],\n",
       "       [ 0.18170649],\n",
       "       [ 0.19081512]])"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we apply log to the target value\n",
    "y = np.log(ytrain_1)\n",
    "X = train_set\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0736579 ,  1.03167675,  1.02673249,  1.02388909,  1.02276863,\n",
       "        1.01835641,  1.01627523,  1.01572017,  1.01226948,  1.01219173,\n",
       "        1.01185431,  1.01123166,  1.01063394,  1.01008171,  1.00994968,\n",
       "        1.00968399,  1.00934976,  1.00927881,  1.00876228,  1.00862622,\n",
       "        1.00846177,  1.0082354 ,  1.0081347 ,  1.00793285,  1.0078782 ,\n",
       "        1.00773243,  1.00759024,  1.00746949,  1.00738979,  1.00707726])"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)                \n",
    "t_train = scaler.transform(X)\n",
    "pca_hp = PCA(30)\n",
    "x_fit = pca_hp.fit_transform(t_train)\n",
    "np.exp(pca_hp.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "#with pca\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x_fit, y, test_size=0.33, random_state=42)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "from sklearn.cross_validation import KFold, cross_val_score, cross_val_predict\n",
    "k_fold = KFold(len(y), n_folds=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.891390797962\n",
      "Cross validation test scores are: \n",
      " [ 0.83455253  0.87354694  0.82448562  0.90395373  0.81897824]\n",
      "Cross validation test scores mean is: \n",
      " 0.851103412701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Fit Random Forest on Training Set\n",
    "regressor = RandomForestRegressor(n_estimators=300, random_state=0)\n",
    "model_random_forest = regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Score model\n",
    "cross_valid_scores = cross_val_score(model_random_forest, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", model_random_forest.score(X_test, y_test)) \n",
    "\n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests\n",
    "#print(\"Cross validation test prediction is: \\n\", cross_val_predict(model_random_forest, X_test, y_test, cv=5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.00172400224692\n"
     ]
    }
   ],
   "source": [
    "predictions_1 = model_random_forest.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.706417901755\n",
      "Cross validation test scores are: \n",
      " [ 0.52521506  0.74023667  0.62815859  0.64564213  0.69742533]\n",
      "Cross validation test scores mean is: \n",
      " 0.647335557725\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "knn = neighbors.KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "          metric_params=None, n_jobs=1, n_neighbors=k, p=2,\n",
    "          weights='uniform')\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "cross_valid_scores = cross_val_score(knn, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", knn.score(X_test, y_test)) \n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.0046601594297\n"
     ]
    }
   ],
   "source": [
    "predictions_2 = knn.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.874399983596\n",
      "Cross validation test scores are: \n",
      " [ -5.19520395e+10  -5.82173491e+10  -2.44956135e+12  -3.37763999e+11\n",
      "  -1.44394248e+12]\n",
      "Cross validation test scores mean is: \n",
      " -868287443661.0\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "regressor = LinearRegression() \n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Score model\n",
    "cross_valid_scores = cross_val_score(regressor, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", regressor.score(X_test, y_test)) \n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests\n",
    "#print(\"Cross validation test prediction is: \\n\", cross_val_predict(regressor, X_test, y_test, cv=5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.00199370501239\n"
     ]
    }
   ],
   "source": [
    "predictions_3 = regressor.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with ridge regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check what alpha value is better for the model\n",
    "\n",
    "for i in range (-5, 5):\n",
    "    alpha = 10**i\n",
    "    rm = linear_model.Ridge(alpha=alpha)\n",
    "    ridge_model = rm.fit(X_train, y_train)\n",
    "    preds_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "    plt.scatter(preds_ridge, y_test, alpha=.75, color='b')\n",
    "    plt.xlabel('Predicted Price')\n",
    "    plt.ylabel('Actual Price')\n",
    "    plt.title('Ridge Regularization with alpha = {}'.format(alpha))\n",
    "    overlay = 'R^2 is: {}\\nRMSE is: {}'.format(\n",
    "                    ridge_model.score(X_test, y_test),\n",
    "                    mean_squared_error(y_test, preds_ridge))\n",
    "    plt.annotate(s=overlay,xy=(12.1,10.6),size='x-large')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.895126227325\n",
      "Cross validation test scores are: \n",
      " [ 0.83331301  0.85853039  0.85140706  0.91007006  0.87390354]\n",
      "Cross validation test scores mean is: \n",
      " 0.865444812833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "linm = linear_model.Ridge(alpha = 10)\n",
    "\n",
    "linm.fit(X_train, y_train)\n",
    "\n",
    "# Score model\n",
    "cross_valid_scores = cross_val_score(linm, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", linm.score(X_test, y_test)) \n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests\n",
    "#print(\"Cross validation test prediction is: \\n\", cross_val_predict(linm, X_test, y_test, cv=5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 0.0016647081126\n"
     ]
    }
   ],
   "source": [
    "predictions = linm.predict(X_test)\n",
    "print(\"Mean Squared Error : \" + str(mean_squared_error(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP with PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.901394582117\n",
      "Cross validation test scores are: \n",
      " [-0.0031029   0.88320437  0.82565631  0.90123692  0.87589606]\n",
      "Cross validation test scores mean is: \n",
      " 0.696578153899\n"
     ]
    }
   ],
   "source": [
    "mlp_regressor = MLPRegressor(solver='lbfgs',hidden_layer_sizes = (200,5,5),alpha = 1.0, activation = 'relu', max_iter = 100)\n",
    "mlp_regressor.fit(X_train1,y_train1)\n",
    "\n",
    "#Score model\n",
    "cross_valid_scores = cross_val_score(mlp_regressor, X_test1, y_test1,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", mlp_regressor.score(X_test1, y_test1)) \n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests\n",
    "#print(\"Cross validation test prediction is: \\n\", cross_val_predict(mlp_regressor, X_test, y_test, cv=5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 0.00156520772457\n"
     ]
    }
   ],
   "source": [
    "predictions7 = mlp_regressor.predict(X_test1)\n",
    "print(\"Mean Squared Error : \" + str(mean_squared_error(y_test1,predictions7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.894508466998\n",
      "Cross validation test scores are: \n",
      " [ 0.27169142  0.25420727  0.20858004  0.33293683  0.21070622]\n",
      "Cross validation test scores mean is: \n",
      " 0.255624358004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# SVM\n",
    "svr_model = SVR(kernel='rbf', C=2, epsilon=0.05)\n",
    "svr_model.fit(X, y)\n",
    "\n",
    "# Score model\n",
    "cross_valid_scores = cross_val_score(svr_model, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", svr_model.score(X_test, y_test)) \n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests\n",
    "#print(\"Cross validation test prediction is: \\n\", cross_val_predict(svr_model, X_test, y_test, cv=5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 0.00167451409747\n"
     ]
    }
   ],
   "source": [
    "predictions_8 = svr_model.predict(X_test)\n",
    "print(\"Mean Squared Error : \" + str(mean_squared_error(y_test,predictions_8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.999999874552\n",
      "Cross validation test scores are: \n",
      " [ 0.73238372  0.59798577  0.83333007  0.64422461  0.68834845]\n",
      "Cross validation test scores mean is: \n",
      " 0.69925452351\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "basic_decision_tree = DecisionTreeRegressor()\n",
    "\n",
    "# Fit model\n",
    "basic_decision_tree.fit(X, y)\n",
    "\n",
    "# Score model\n",
    "cross_valid_scores = cross_val_score(basic_decision_tree, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", basic_decision_tree.score(X_test, y_test)) \n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests\n",
    "#print(\"Cross validation test prediction is: \\n\", cross_val_predict(basic_decision_tree, X_test, y_test, cv=5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 1.99129173656e-09\n"
     ]
    }
   ],
   "source": [
    "predictions_5 = basic_decision_tree.predict(X_test)\n",
    "print(\"Mean Squared Error : \" + str(mean_squared_error(y_test,predictions_5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = np.arange(0.0, 0.09, 0.0015)\n",
    "learning_rates\n",
    "best_learning_rates = [0.0885, 0.0735, 0.0705, 0.0615, 0.06, 0.0585, 0.057, 0.0555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find best parameters\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "actual_values = y_test\n",
    "\n",
    "for i in best_learning_rates:\n",
    "    n_estimators = 1000\n",
    "    my_model = XGBRegressor(n_estimators=n_estimators,learning_rate=i)\n",
    "    xgboost_model = my_model.fit(X_train, y_train, early_stopping_rounds=5, \n",
    "                 eval_set=[(X_test, y_test)], verbose=False)\n",
    "    preds_xgboost = xgboost_model.predict(X_test)\n",
    "\n",
    "    plt.scatter(preds_xgboost, actual_values, alpha=.75, color='b')\n",
    "    plt.xlabel('Predicted Price')\n",
    "    plt.ylabel('Actual Price')\n",
    "    plt.title('XGBoost with  = {}'.format(n_estimators))\n",
    "    overlay = 'R^2 is: {}\\nRMSE is: {}\\nlearning Rate is: {}'.format(\n",
    "                        xgboost_model.score(X_test, y_test),\n",
    "                        mean_squared_error(y_test, preds_xgboost),\n",
    "                        i)\n",
    "    plt.annotate(s=overlay,xy=(12.1,10.6),size='x-large')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.913901916392\n",
      "Cross validation test scores are: \n",
      " [ 0.86448621  0.87604771  0.84397111  0.8966852   0.87625473]\n",
      "Cross validation test scores mean is: \n",
      " 0.871488990251\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "XGBoost = XGBRegressor(n_estimators = 1000,learning_rate=0.0585)\n",
    "XGBoost.fit(X_train, y_train)\n",
    "\n",
    "# Score model\n",
    "cross_valid_scores = cross_val_score(XGBoost, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", XGBoost.score(X_test, y_test)) \n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests\n",
    "#print(\"Cross validation test prediction is: \\n\", cross_val_predict(XGBoost, X_test, y_test, cv=5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.00136667323588\n"
     ]
    }
   ],
   "source": [
    "prediction = XGBoost.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.899338221327\n",
      "Cross validation test scores are: \n",
      " [ 0.86944381  0.87115553  0.85208326  0.90804566  0.89221629]\n",
      "Cross validation test scores mean is: \n",
      " 0.878588910258\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "lasso.fit(X_train, y_train)\n",
    "# Score model\n",
    "cross_valid_scores = cross_val_score(lasso, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", lasso.score(X_test, y_test)) \n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests\n",
    "#print(\"Cross validation test prediction is: \\n\", cross_val_predict(lasso, X_test, y_test, cv=5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.00159784925545\n"
     ]
    }
   ],
   "source": [
    "predictions_lasso = lasso.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_lasso)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.900368215086\n",
      "Cross validation test scores are: \n",
      " [ 0.86977879  0.86942889  0.85317722  0.90874092  0.89418217]\n",
      "Cross validation test scores mean is: \n",
      " 0.879061599008\n"
     ]
    }
   ],
   "source": [
    "# Elastic Net regression\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "ENet.fit(X_train, y_train)\n",
    "# Score model\n",
    "cross_valid_scores = cross_val_score(ENet, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", ENet.score(X_test, y_test)) \n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests\n",
    "#print(\"Cross validation test prediction is: \\n\", cross_val_predict(ENet, X_test, y_test, cv=5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.00158149970568\n"
     ]
    }
   ],
   "source": [
    "predictions_ENet = ENet.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_ENet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.909319187266\n",
      "Cross validation test scores are: \n",
      " [ 0.87631737  0.86176166  0.84243848  0.92680607  0.8957511 ]\n",
      "Cross validation test scores mean is: \n",
      " 0.8806149358\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting regression\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "GBoost.fit(X_train, y_train)\n",
    "# Score model\n",
    "cross_valid_scores = cross_val_score(GBoost, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", GBoost.score(X_test, y_test)) \n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests\n",
    "#print(\"Cross validation test prediction is: \\n\", cross_val_predict(GBoost, X_test, y_test, cv=5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.0014394169368\n"
     ]
    }
   ],
   "source": [
    "predictions_GBoost = GBoost.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_GBoost)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.919875495568\n",
      "Cross validation test scores are: \n",
      " [ 0.86495789  0.86111566  0.86559784  0.90077718  0.88233529]\n",
      "Cross validation test scores mean is: \n",
      " 0.874956770374\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "model_lgb.fit(X_train, y_train.ravel())\n",
    "# Score model\n",
    "cross_valid_scores = cross_val_score(model_lgb, X_test, y_test.ravel(),cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", model_lgb.score(X_test, y_test.ravel())) \n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests\n",
    "#print(\"Cross validation test prediction is: \\n\", cross_val_predict(model_lgb, X_test, y_test, cv=5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.00127185195252\n"
     ]
    }
   ],
   "source": [
    "predictions_model_lgb = model_lgb.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_model_lgb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is: \n",
      " 0.852873126478\n",
      "Cross validation test scores are: \n",
      " [ 0.78250133  0.8577517   0.77997746  0.84220686  0.77926063]\n",
      "Cross validation test scores mean is: \n",
      " 0.808339593914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ada_boost = AdaBoostRegressor(n_estimators=100)\n",
    "ada_boost.fit(X_train, y_train)\n",
    "# Score model\n",
    "cross_valid_scores = cross_val_score(ada_boost, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test score is: \\n\", ada_boost.score(X_test, y_test)) \n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean()) # mean of all cross validations tests\n",
    "#print(\"Cross validation test prediction is: \\n\", cross_val_predict(model_lgb, X_test, y_test, cv=5 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avereging Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enet regression + GBoost + LGBM + Lasso regression (Best Score):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: \n",
      " 0.918914225214\n",
      "Cross validation test scores are: \n",
      " [ 0.88497388  0.88172469  0.85980221  0.92577928  0.9061036 ]\n",
      "Cross validation test scores mean is: \n",
      " 0.89167673175\n"
     ]
    }
   ],
   "source": [
    "# Averging Models\n",
    "\n",
    "averaged_models = AveragingModels(models = (ENet, GBoost, model_lgb, lasso))\n",
    "\n",
    "averaged_models.fit(X_train, y_train)\n",
    "\n",
    "cross_valid_scores = cross_val_score(averaged_models, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "\n",
    "print (\"Test Score: \\n\", averaged_models.score(X_test, y_test))\n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge LR + RandomForest + ENet + Lasso regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: \n",
      " 0.910048588255\n",
      "Cross validation test scores are: \n",
      " [ 0.87204773  0.89324598  0.85526886  0.9273746   0.88903652]\n",
      "Cross validation test scores mean is: \n",
      " 0.88739473858\n"
     ]
    }
   ],
   "source": [
    "\n",
    "averaged_models_1 = AveragingModels(models = (linm, model_random_forest, ENet, lasso))\n",
    "\n",
    "averaged_models_1.fit(X_train, y_train)\n",
    "\n",
    "cross_valid_scores = cross_val_score(averaged_models_1, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test Score: \\n\", averaged_models_1.score(X_test, y_test))\n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.00142783882997\n"
     ]
    }
   ],
   "source": [
    "predictions = averaged_models_1.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test.ravel(),predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging: Using Three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: \n",
      " 0.882495794937\n",
      "Cross validation test scores are: \n",
      " [ 0.82099872  0.85378185  0.74728023  0.86251261  0.86012733]\n",
      "Cross validation test scores mean is: \n",
      " 0.828940148428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bagging = BaggingRegressor(linear_model.Ridge(alpha = 10),max_samples=0.5, max_features=0.5)\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "cross_valid_scores = cross_val_score(bagging, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test Score: \\n\", bagging.score(X_test, y_test))\n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.00186519659247\n"
     ]
    }
   ],
   "source": [
    "predictions_b = bagging.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: \n",
      " 0.904769483195\n",
      "Cross validation test scores are: \n",
      " [ 0.83387022  0.86906144  0.75682718  0.90596658  0.8905166 ]\n",
      "Cross validation test scores mean is: \n",
      " 0.851248404896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bagging_1 = BaggingRegressor(GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5),max_samples=0.5, max_features=0.5)\n",
    "bagging_1.fit(X_train, y_train)\n",
    "\n",
    "cross_valid_scores = cross_val_score(bagging_1, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test Score: \\n\", bagging_1.score(X_test, y_test))\n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.00186519659247\n"
     ]
    }
   ],
   "source": [
    "predictions_b1 = bagging.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_b1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: \n",
      " 0.91631968757\n",
      "Cross validation test scores are: \n",
      " [ 0.84645142  0.88986871  0.78449521  0.91788313  0.90011494]\n",
      "Cross validation test scores mean is: \n",
      " 0.867762680451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bagging_2 = BaggingRegressor(lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11),max_samples=0.5, max_features=0.5)\n",
    "bagging_2.fit(X_train, y_train)\n",
    "\n",
    "cross_valid_scores = cross_val_score(bagging_2, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test Score: \\n\", bagging_2.score(X_test, y_test))\n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.00186519659247\n"
     ]
    }
   ],
   "source": [
    "predictions_b2 = bagging.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions_b2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averging bagging models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: \n",
      " 0.918914225214\n",
      "Cross validation test scores are: \n",
      " [ 0.85852217  0.87341289  0.80284858  0.92366005  0.88486621]\n",
      "Cross validation test scores mean is: \n",
      " 0.868661979687\n"
     ]
    }
   ],
   "source": [
    "#Best version\n",
    "averaged_models_2 = AveragingModels(models = (bagging, bagging_1, bagging_2, linm))\n",
    "\n",
    "averaged_models_2.fit(X_train, y_train)\n",
    "\n",
    "cross_valid_scores = cross_val_score(averaged_models_2, X_test, y_test,cv=5, n_jobs=1)\n",
    "\n",
    "print (\"Test Score: \\n\", averaged_models.score(X_test, y_test))\n",
    "print(\"Cross validation test scores are: \\n\", cross_valid_scores) #return a np.array of each test trill\n",
    "print(\"Cross validation test scores mean is: \\n\", cross_valid_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error : 0.00146586892081\n"
     ]
    }
   ],
   "source": [
    "predictions = averaged_models_2.predict(X_test)\n",
    "print(\"Mean squared Error : \" + str(mean_squared_error(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "%store -r test_ID\n",
    "submission['Id'] = test_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 291)"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = test_set.select_dtypes(\n",
    "        include=[np.number]).interpolate()\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = averaged_models.predict(feats)\n",
    "final_predictions = np.exp(predictions)\n",
    "#final_predictions = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>121268.786360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>164682.988465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>185787.486084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>196628.197051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>194620.563407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1466</td>\n",
       "      <td>174409.649002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1467</td>\n",
       "      <td>179434.717592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1468</td>\n",
       "      <td>162407.073930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1469</td>\n",
       "      <td>198668.769638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1470</td>\n",
       "      <td>122857.170439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  121268.786360\n",
       "1  1462  164682.988465\n",
       "2  1463  185787.486084\n",
       "3  1464  196628.197051\n",
       "4  1465  194620.563407\n",
       "5  1466  174409.649002\n",
       "6  1467  179434.717592\n",
       "7  1468  162407.073930\n",
       "8  1469  198668.769638\n",
       "9  1470  122857.170439"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['SalePrice'] = final_predictions\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv(\"log_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
